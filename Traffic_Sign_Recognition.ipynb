{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "84b6ac93",
      "metadata": {
        "id": "84b6ac93",
        "outputId": "ee9b7406-3e0b-4dee-da8b-cd26ee6e06b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras.layers.convolutional'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-0bd0720711c5>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.layers.convolutional'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "# Importing to_categorical from tensorflow.keras.utils instead of keras.utils.np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# ... rest of the code remains the same ...\n",
        "\n",
        "path = \"Dataset\"\n",
        "labelFile = 'labels.csv'\n",
        "batch_size_val=32\n",
        "epochs_val=10\n",
        "imageDimesions = (32,32,3)\n",
        "testRatio = 0.2\n",
        "validationRatio = 0.2\n",
        "\n",
        "count = 0\n",
        "images = []\n",
        "classNo = []\n",
        "myList = os.listdir(path)\n",
        "print(\"Total Classes Detected:\",len(myList))\n",
        "noOfClasses=len(myList)\n",
        "print(\"Importing Classes.....\")\n",
        "for x in range (0,len(myList)):\n",
        "    myPicList = os.listdir(path+\"/\"+str(count))\n",
        "    for y in myPicList:\n",
        "        curImg = cv2.imread(path+\"/\"+str(count)+\"/\"+y)\n",
        "        images.append(curImg)\n",
        "        classNo.append(count)\n",
        "    print(count, end =\" \")\n",
        "    count +=1\n",
        "print(\" \")\n",
        "images = np.array(images)\n",
        "classNo = np.array(classNo)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, classNo, test_size=testRatio)\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validationRatio)\n",
        "\n",
        "\n",
        "print(\"Data Shapes\")\n",
        "print(\"Train\",end = \"\");print(X_train.shape,y_train.shape)\n",
        "print(\"Validation\",end = \"\");print(X_validation.shape,y_validation.shape)\n",
        "print(\"Test\",end = \"\");print(X_test.shape,y_test.shape)\n",
        "\n",
        "\n",
        "data=pd.read_csv(labelFile)\n",
        "print(\"data shape \",data.shape,type(data))\n",
        "\n",
        "num_of_samples = []\n",
        "cols = 5\n",
        "num_classes = noOfClasses\n",
        "\n",
        "def grayscale(img):\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "    return img\n",
        "def equalize(img):\n",
        "    img =cv2.equalizeHist(img)\n",
        "    return img\n",
        "def preprocessing(img):\n",
        "    img = grayscale(img)\n",
        "    img = equalize(img)\n",
        "    img = img/255\n",
        "    return img\n",
        "\n",
        "X_train=np.array(list(map(preprocessing,X_train)))\n",
        "X_validation=np.array(list(map(preprocessing,X_validation)))\n",
        "X_test=np.array(list(map(preprocessing,X_test)))\n",
        "\n",
        "\n",
        "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
        "X_validation=X_validation.reshape(X_validation.shape[0],X_validation.shape[1],X_validation.shape[2],1)\n",
        "X_test=X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\n",
        "\n",
        "\n",
        "dataGen= ImageDataGenerator(width_shift_range=0.1,\n",
        "                            height_shift_range=0.1,\n",
        "                            zoom_range=0.2,\n",
        "                            shear_range=0.1,\n",
        "                            rotation_range=10)\n",
        "dataGen.fit(X_train)\n",
        "batches= dataGen.flow(X_train,y_train,batch_size=20)\n",
        "X_batch,y_batch = next(batches)\n",
        "\n",
        "\n",
        "y_train = to_categorical(y_train,noOfClasses)\n",
        "y_validation = to_categorical(y_validation,noOfClasses)\n",
        "y_test = to_categorical(y_test,noOfClasses)\n",
        "\n",
        "\n",
        "def myModel():\n",
        "    model= Sequential()\n",
        "    model.add((Conv2D(60,(5,5),input_shape=(imageDimesions[0],imageDimesions[1],1),activation='relu')))  # ADDING MORE CONVOLUTION LAYERS = LESS FEATURES BUT CAN CAUSE ACCURACY TO INCREASE\n",
        "    model.add((Conv2D(60, (5,5), activation='relu')))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add((Conv2D(30, (3,3),activation='relu')))\n",
        "    model.add((Conv2D(30, (3,3), activation='relu')))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(500,activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(noOfClasses,activation='softmax'))\n",
        "    model.compile(Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = myModel()\n",
        "print(model.summary())\n",
        "history = model.fit(\n",
        "       dataGen.flow(X_train, y_train, batch_size=batch_size_val),\n",
        "       steps_per_epoch=len(X_train) // batch_size_val,  # Corrected calculation\n",
        "       epochs=epochs_val,\n",
        "       validation_data=(X_validation, y_validation),\n",
        "       shuffle=True\n",
        "   )\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['training','validation'])\n",
        "plt.title('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.figure(2)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['training','validation'])\n",
        "plt.title('Acurracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "score =model.evaluate(X_test,y_test,verbose=0)\n",
        "print('Test Score:',score[0])\n",
        "print('Test Accuracy:',score[1])\n",
        "\n",
        "model.save(\"model.h5\")"
      ]
    },
    {
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "# Importing to_categorical from tensorflow.keras.utils instead of keras.utils.np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# ... rest of the code remains the same ..."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "wDezTJRhfy22"
      },
      "id": "wDezTJRhfy22",
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "history = model.fit(\n",
        "       dataGen.flow(X_train, y_train, batch_size=batch_size_val),\n",
        "       steps_per_epoch=len(X_train) // batch_size_val,  # Corrected calculation\n",
        "       epochs=epochs_val,\n",
        "       validation_data=(X_validation, y_validation),\n",
        "       shuffle=True\n",
        "   )"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "gQhZv-PkfPrl"
      },
      "id": "gQhZv-PkfPrl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f033e2c",
      "metadata": {
        "id": "1f033e2c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}